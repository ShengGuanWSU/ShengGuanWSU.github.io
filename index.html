<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Sheng Guan</title>

        <link href="css/bootstrap.min.css" rel="stylesheet">
        <script src="https://kit.fontawesome.com/a868962991.js" crossorigin="anonymous"></script>
        <link rel="stylesheet" href="./assets/font-awesome-4.7.0/css/font-awesome.min.css"/>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    </head>

    <body>

      <div style="height:10px;"></div>
      <!-- Navigation bar -->
      
      <div class="navbar navbar-default  navbar-fixed-top bg-info">
        <div class="container">
          <div class="navbar-header">
          
            <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
          </div>
          <div class="navbar-collapse collapse" id="navbar-main">
             
            <ul class="nav navbar-nav navbar-left">
              <li ><a href="">Home</a></li>
              <li ><a href="paper.html">Publications</a></li>
              <li ><a href="#experiences">Experiences</a></li>
              <li ><a href="#services">Services</a></li>
              <li ><a href="#honor">Honors</a></li>
            </ul>
          </div>
        </div>
      </div>

      <div style="height:80px;"></div>
      

      <!-- end of navigation bar -->

      <!-- CONTENTS -->
      <div class="container">
        <!-- Aboutme -->
        <!--<div id="aboutme"></div> -->
        <div class="row">
          <div class="col-xs-6 col-sm-4 col-md-2">
            <a class="thumbnail">
              <img src="images/photo_ShengGuan.jpg" alt="Sheng Guan" class="img-rounded">
            </a>            
          </div>

          <div class="col-xs-10 col-sm-6 col-md-3">
            <h1 class="text-info">Sheng Guan</h1><b><font style="font-family:STKaiti" size="3"></font></b>
            <h4 class="text-info">Data Mining and Machine Learning Laboratory<br> School of Computing and Augmented Intelligence<br> Arizona State University</h4>
            <h5>
              <a href="mailto:kaize.ding@asu.edu" class="text-info" title="e-Mail"><i class="fas fa-envelope-square fa-2x"></i></a>
              <a href="https://scholar.google.com/citations?user=PI3myr8AAAAJ" class="text-info" title="Google Scholar"><i class="ai ai-google-scholar-square ai-2x">
              </i></a>
              <a href="https://github.com/kaize0409" class="text-info" title="GitHub"><i class="fa fa-github-square fa-2x"></i></a>
              <a href="https://www.linkedin.com/in/kaize-ding-605a44109/" class="text-info" title="LinkedIn"><i class="fa fa-linkedin-square fa-2x"></i></a>
              <a href="" class="text-info" title="CV"><i class="ai ai-cv-square ai-2x"></i></a>
              <a href="https://twitter.com/kaize0409" class="text-info" title="Twitter"><i class="fa fa-twitter-square fa-2x"></i></a>
            </h5>
          </div>
        </div> <!-- end of Aboutme -->

         <p align="justify">
              <b>About me:</b> I am a PhD student of <a href="http://cidse.engineering.asu.edu/">Computing Science and Engineering</a>, <a href="http://www.asu.edu/">Arizona State University</a>. I work as a research assistant at <a href="http://dmml.asu.edu/">Data Mining and Machine Learning Laboratory</a>, advised by Professor <a href="http://www.public.asu.edu/~huanliu/">Huan Liu</a>. Before that, I obtained my master and bachelor degrees from <a href="https://english.bupt.edu.cn/">Beijing University of Posts and Telecommunications (BUPT)</a>.
              
         </p>
         <p align="justify">         
              <b>Research Interest:</b> My research interests generally lie in data mining and machine learning, currently I'm focusing on minimally-supervised learning (e.g., few-shot learning, weakly-supervised learning, self-supervised learning), with a special focus on graph and text data.
              
         </p>
        
       <!-- 
        <hr>
         <p align="justify", color='red'>
            <b>I am on the job market this year. Please feel free to contact me if you are interested.</b> 
         </p>
	-->
        
        <hr>
        <!-- News -->
        <div class="row" id="news" style="padding-top:60px; margin-top:-60px;">
          <div class="col-md-12">
            <h2>News</h2>
          </div>
        </div>
      
      <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">02/2022</span>
          </div>
          <div class="col-sm-11 col-md-11">
            WSDM 2022 Tutorial - <a href="https://sites.google.com/view/wsdm2022-tutorial-gmsl/">Graph Minimally-supervised Learning</a>.
          </div>
        </div>
      <div style="height:3px;"></div>
	
	<div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-primary">02/2022</span>
          </div>
          <div class="col-sm-11 col-md-11">
            Check out our survey on <a href="https://arxiv.org/abs/2202.08235">Data Augmentation for Deep Graph Learning</a>.
          </div>
        </div>
      <div style="height:3px;"></div>
	
      <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-primary">12/2021</span>
          </div>
          <div class="col-sm-11 col-md-11">
            One paper got accepted in AAAI 2022.
          </div>
        </div>
      <div style="height:3px;"></div>

      <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-success">11/2021</span>
          </div>
          <div class="col-sm-11 col-md-11">
            Invited to be PC member of KDD 2022, IJCAI 2022.
          </div>
        </div>
      <div style="height:3px;"></div>

      <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-primary">12/2021</span>
          </div>
          <div class="col-sm-11 col-md-11">
            One paper got accepted in AAAI 2022.
          </div>
        </div>
      <div style="height:3px;"></div>
      
      <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-primary">10/2021</span>
          </div>
          <div class="col-sm-11 col-md-11">
            One paper got accepted in WSDM 2022.
          </div>
        </div>
      <div style="height:3px;"></div>

       <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-primary">08/2021</span>
          </div>
          <div class="col-sm-11 col-md-11">
            One paper got accepted in EMNLP 2021. 
          </div>
        </div>
        <div style="height:3px;"></div>

       <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-primary">08/2021</span>
          </div>
          <div class="col-sm-11 col-md-11">
            Two papers got accepted in CIKM 2021.
          </div>
        </div>
        <div style="height:3px;"></div>

      <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-success">08/2021</span>
          </div>
          <div class="col-sm-11 col-md-11">
            Invited to be PC member of WSDM 2022.
          </div>
        </div>
        <div style="height:3px;"></div>

       <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-primary">01/2021</span>
          </div>
          <div class="col-sm-11 col-md-11">
            One paper got accepted in WWW 2021.
          </div>
        </div>
        <div style="height:3px;"></div>

      <!--<div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-primary">12/2020</span>
          </div>
          <div class="col-sm-11 col-md-11">
            One paper got accepted in SDM 2021.
          </div>
        </div>
      <div style="height:3px;"></div>       

       <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-primary">12/2020</span>
          </div>
          <div class="col-sm-11 col-md-11">
            One paper got accepted in AAAI 2021.
          </div>
        </div>
        <div style="height:3px;"></div>
       
        <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-success">12/2020</span>
          </div>
          <div class="col-sm-11 col-md-11">
            Invited to be PC member of NAACL 2021, ACL 2021. 
          </div>
        </div>
        <div style="height:3px;"></div>-->

       
      <!--
       <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-success">11 / 2018</span>
          </div>
          <div class="col-sm-11 col-md-11">
            Our paper about <a href="https://ojs.aaai.org//index.php/AAAI/article/view/4352">Online Feature Selection</a> was accepted by AAAI'19.
          </div>
        </div>
        <div style="height:3px;"></div>
        
        <div class="row">
              <div class="col-sm-1 col-md-1">
                <span class="label label-info">01 / 2018</span>
              </div>
              <div class="col-sm-11 col-md-11">
                I joined <a href="https://www.aitrics.com/en">AITRICS</a> (South Korea) as a research intern. 
              </div>
            </div>
            <div style="height:3px;"></div>

            <div class="row">
              <div class="col-sm-1 col-md-1">
                <span class="label label-info">05 / 2017</span>
              </div>
              <div class="col-sm-11 col-md-11">
                Our team ranked 6th (top 1%) at the <a href="https://www.kaggle.com/c/youtube8m/leaderboard">Google Cloud & Youtube-8M Video Understanding Challenge</a>. 
              </div>
            </div>
            <div style="height:3px;"></div>
        -->

        <!-- old news -->
        
        <div class="row">
          <div class="col-sm-1 col-md-1">
          </div>
          <div class="col-sm-11 col-md-11">
            <button type="button" class="btn btn-default btn-xs" data-toggle="collapse" data-target="#old_news">see older...</button>
          </div>
        </div>
        <div style="height:3px;"></div>

        <div id="old_news" class="collapse">
	
	     <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-primary">12/2020</span>
          </div>
          <div class="col-sm-11 col-md-11">
            One paper got accepted in SDM 2021.
          </div>
        </div>
      <div style="height:3px;"></div>       

       <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-primary">12/2020</span>
          </div>
          <div class="col-sm-11 col-md-11">
            One paper got accepted in AAAI 2021.
          </div>
        </div>
        <div style="height:3px;"></div>
       
        <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-success">12/2020</span>
          </div>
          <div class="col-sm-11 col-md-11">
            Invited to be PC member of NAACL 2021, ACL 2021. 
          </div>
        </div>
        <div style="height:3px;"></div>	

	<div class="row">
              <div class="col-sm-1 col-md-1">
                <span class="label label-info">09/2017</span>
              </div>
              <div class="col-sm-11 col-md-11">
                I enrolled as a PhD student at ASU. 
              </div>
            </div>
            <div style="height:3px;"></div>
	
        </div>
        
        <!-- end of collapsed news -->

        <!--Colors = label-default, label-primary, label-success, label-info, label-warning, label-danger-->

        <!-- end of news -->
        <hr>






        <!-- Research -->
        <div class="row"  id="research" style="padding-top:60px; margin-top:-60px;">
          <div class="col-md-12">
            <h2>Selected Papers</h2>
            <p>
              <a href="https://scholar.google.com/citations?user=PI3myr8AAAAJ">[Google Scholar]</a> <a href="paper.html">[Full List]</a>
            </p>

	    
	    <div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                  <img src="image/Meta-PN.png" alt="Meta Propagation Networks for Graph Few-shot Semi-supervised Learning">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Meta Propagation Networks for Graph Few-shot Semi-supervised Learning</strong><br>
                <u>Kaize Ding</u>, Jianling Wang, James Caverlee and Huan Liu<br>
                <em>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>) </em> 2022.<br>
                <a href="https://arxiv.org/pdf/2112.09810.pdf"> <button type="button" class="btn btn-primary btn-xs"> pdf </button> </a>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bibtex15">bibtex</button>
                <div id="bibtex15" class="collapse">
                  <pre><tt>@InProceedings{ding2022meta,
  title &nbsp&nbsp&nbsp&nbsp= {Meta Propagation Networks for Graph Few-shot Semi-supervised Learning},
  author &nbsp&nbsp = {Ding, Kaize and Wang, Jianling and Caverlee, James and Liu, Huan},
  booktitle = {AAAI},
  year &nbsp&nbsp&nbsp = {2022},
}</tt></pre>
                </div>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#abstract15">abstract</button>
                <div id="abstract15" class="collapse">
                  <p class="bg-success">
                     Inspired by the extensive success of deep learning, graph neural networks (GNNs) have been proposed to learn expressive node representations and demonstrated promising performance in various graph learning tasks. However, existing endeavors predominately focus on the conventional semi-supervised setting where relatively abundant gold-labeled nodes are provided. While it is often impractical due to the fact that data labeling is unbearably laborious and requires intensive domain knowledge, especially when considering the heterogeneity of graph-structured data. Under the few-shot semi-supervised setting, the performance of most of the existing GNNs is inevitably undermined by the overfitting and oversmoothing issues, largely owing to the shortage of labeled data. In this paper, we propose a decoupled network architecture equipped with a novel meta-learning algorithm to solve this problem. In essence, our framework Meta-PN infers high-quality pseudo labels on unlabeled nodes via a meta-learned label propagation strategy, which effectively augments the scarce labeled data while enabling large receptive fields during training. Extensive experiments demonstrate that our approach offers easy and substantial performance gains compared to existing techniques on various benchmark datasets. 
                  </p>
                </div>
                <a href="https://github.com/kaize0409/Meta-PN"> <button type="button" class="btn btn-primary btn-xs"> code </button> </a>
                <div style="height:30px;"></div>
              </div>
            </div>


            <div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                  <img src="image/LTSL.png" alt="LTSL model">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Learning to Selectively Learn for Weakly-supervised Paraphrase Generation</strong><br>
                <u>Kaize Ding</u>, Dingcheng Li, Alexander Hanbo Li, Xing Fan, Chenlei Guo, Yang Liu, and Huan Liu<br>
                <em>Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>)  </em> 2021.<br>
                <a href="https://arxiv.org/pdf/2109.12457.pdf"> <button type="button" class="btn btn-primary btn-xs"> pdf </button> </a>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bibtex14">bibtex</button>
                <div id="bibtex14" class="collapse">
                  <pre><tt>@InProceedings{ding2021learning,
  title &nbsp&nbsp&nbsp&nbsp= {Learning to Selectively Learn for Weakly-supervised Paraphrase Generation},
  author &nbsp&nbsp = {Ding, Kaize and Li, Dingcheng and Li, Alexander Hanbo and Fan, Xing and Guo, Chenlei and Liu, Yang and Liu, Huan},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year &nbsp&nbsp&nbsp = {2021},
}</tt></pre>
                </div>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#abstract14">abstract</button>
                <div id="abstract14" class="collapse">
                  <p class="bg-success">
                    Paraphrase generation is a longstanding NLP task that has diverse applications for downstream NLP tasks. However, the effectiveness of existing efforts predominantly relies on large amounts of golden labeled data. Though unsupervised endeavors have been proposed to address this issue, they may fail to generate meaningful paraphrases due to the lack of supervision signals. In this work, we go beyond the existing paradigms and propose a novel approach to generate high-quality paraphrases with weak supervision data. Specifically, we tackle the weakly-supervised paraphrase generation problem by: (1) obtaining abundant weakly-labeled parallel sentences via retrieval-based pseudo paraphrase expansion; and (2) developing a meta-learning framework to progressively select valuable samples for fine-tuning a pre-trained language model, i.e., BART, on the sentential paraphrasing task. We demonstrate that our approach achieves significant improvements over existing unsupervised approaches, and is even comparable in performance with supervised state-of-the-arts.
                  </p>
                </div>
                <a href=""> <button type="button" class="btn btn-primary btn-xs"> code </button> </a>
                <div style="height:30px;"></div>
              </div>
            </div>



            <div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                  <img src="image/Meta-GDN.png" alt="">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Few-shot Network Anomaly Detection with Cross-network Meta-learning</strong><br>
                <u>Kaize Ding</u>*, Qinghai Zhou*, Hanghang Tong, and Huan Liu (*equal contribution)<br>
                <em>The Web Conference (formerly <strong>WWW</strong>)</em> 2021.<br>
                <a href="https://arxiv.org/pdf/2102.11165.pdf"> <button type="button" class="btn btn-primary btn-xs"> pdf </button> </a>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bibtex13">bibtex</button>
                <div id="bibtex13" class="collapse">
                  <pre><tt>@InProceedings{ding2021few,
  title &nbsp&nbsp&nbsp&nbsp= {Few-shot Network Anomaly Detection via Cross-network Meta-learning},
  author &nbsp&nbsp = {Ding, Kaize and Zhou, Qinghai and Tong, Hanghang and Liu, Huan},
  booktitle = {Proceedings of the Web Conference 2021},
  year &nbsp&nbsp&nbsp&nbsp&nbsp= {2021}
}</tt></pre>
                </div>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#abstract13">abstract</button>
                <div id="abstract13" class="collapse">
                  <p class="bg-success">
                    In general, graph neural networks (GNNs) adopt the message-passing scheme to capture the information of a node (i.e., nodal attributes, and local graph structure) by iteratively transforming, aggregating the features of its neighbors. Nonetheless, recent studies show that the performance of GNNs can be easily hampered by the existence of abnormal or malicious nodes due to the vulnerability of neighborhood aggregation. Thus it is necessary to learn anomaly-resistant GNNs without the prior knowledge of ground-truth anomalies, given the fact that labeling anomalies is costly and requires intensive domain knowledge.  In order to keep the effectiveness of GNNs on anomaly-contaminated graphs, in this paper, we propose a new framework named RARE-GNN (Reinforced Anomaly-Resistant Graph Neural Networks) which can detect anomalies from the input graph and learn anomaly-resistant GNNs simultaneously. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed framework.
                  </p>
                </div>
                <a href="https://github.com/kaize0409/Meta-GDN"> <button type="button" class="btn btn-primary btn-xs"> code </button> </a>
                <div style="height:30px;"></div>
              </div>
            </div>


            <!--
            <div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail" href="">
                  <img src="./img/SCOT.jpg" alt="Semantic Correspondence as an Optimal Transport Problem">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Towards Anomaly-resistant Graph Neural Networks via Reinforcement Learning (Short Paper)</strong><br>
                <u>Kaize Ding</u>, Xuan Shan, and Huan Liu<br>
                <em>ACM International Conference on Information and Knowledge Management (CIKM) </em> 2021.<br>
                <a href="http://www.public.asu.edu/~kding9/pdf/CIKM2021_RARE-GNN.pdf"> <button type="button" class="btn btn-primary btn-xs"> pdf </button> </a>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bibtex12">bibtex</button>
                <div id="bibtex12" class="collapse">
                  <pre><tt>@InProceedings{ding2021towards,
  title &nbsp&nbsp&nbsp&nbsp= {Towards Anomaly-resistant Graph Neural Networks via Reinforcement Learning},
  author &nbsp&nbsp = {Ding, Kaize and Shan, Xuan and Liu, Huan},
  booktitle = {CIKM},
  year &nbsp&nbsp&nbsp&nbsp&nbsp= {2021}
}</tt></pre>
                </div>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#abstract12">abstract</button>
                <div id="abstract12" class="collapse">
                  <p class="bg-success">
                    
                  </p>
                </div>
                <a href=""> <button type="button" class="btn btn-primary btn-xs"> code </button> </a>
                <div style="height:30px;"></div>
              </div>
            </div>
            -->


            <div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                  <img src="image/HyperGAT.png" alt="Learning to Propagate Labels: Transductive Propagation Network for Few-shot Learning">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Be More with Less: Hypergraph Attention Networks for Inductive Text Classification</strong><br>
                <u>Kaize Ding</u>,  Jianling Wang, Jundong Li, Dingchneg Li, and Huan Liu<br>
                <em>Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>) </em> 2020.<br>
                <a href="https://www.aclweb.org/anthology/2020.emnlp-main.399.pdf"> <button type="button" class="btn btn-primary btn-xs"> pdf </button> </a>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bibtex11">bibtex</button>
                <div id="bibtex11" class="collapse">
                  <pre><tt>@InProceedings{ding2020more,
  title &nbsp&nbsp&nbsp&nbsp= {Be more with less: Hypergraph attention networks for inductive text classification},
  author &nbsp&nbsp = {Ding, Kaize and Wang, Jianling and Li, Jundong and Li, Dingcheng and Liu, Huan},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year &nbsp&nbsp&nbsp = {2020},
}</tt></pre>
                </div>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#abstract11">abstract</button>
                <div id="abstract11" class="collapse">
                  <p class="bg-success">
                    Text classification is a critical research topic with broad applications in natural language processing. Recently, graph neural networks (GNNs) have received increasing attention in the research community and demonstrated their promising results on this canonical task. Despite the success, their performance could be largely jeopardized in practice since they are: (1) unable to capture high-order interaction between words; (2) inefficient to handle large datasets and new documents. To address those issues, in this paper, we propose a principled model -- hypergraph attention networks (HyperGAT), which can obtain more expressive power with less computational consumption for text representation learning. Extensive experiments on various benchmark datasets demonstrate the efficacy of the proposed approach on the text classification task. 
                  </p>
                </div>
                <a href="https://github.com/kaize0409/HyperGAT"> <button type="button" class="btn btn-primary btn-xs"> code </button> </a>
                <div style="height:30px;"></div>
              </div>
            </div>




            <div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                  <img src="image/GPN.png" alt="Adaptive Sparse Confidence-Weighted Learning for Online Feature Selection">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Graph Prototypical Networks for Few-shot Learning on Attributed Networks</strong><br>
                <u>Kaize Ding</u>, Jianling Wang, Jundong Li, Kai Shu, Chenghao Liu, and Huan Liu<br>
                <em>ACM International Conference on Information and Knowledge Management (<strong>CIKM</strong>) </em> 2020.<br>
                <a href="https://arxiv.org/pdf/2006.12739.pdf"> <button type="button" class="btn btn-primary btn-xs"> pdf </button> </a>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bibtex9">bibtex</button>
                <div id="bibtex9" class="collapse">
                  <pre><tt>@InProceedings{ding2020graph,
  title &nbsp&nbsp&nbsp&nbsp= {Graph prototypical networks for few-shot learning on attributed networks},
  author &nbsp&nbsp = {Ding, Kaize and Wang, Jianling and Li, Jundong and Shu, Kai and Liu, Chenghao and Liu, Huan},
  booktitle = {Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
  year &nbsp&nbsp&nbsp = {2020},
}</tt></pre>
                </div>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#abstract9">abstract</button>
                <div id="abstract9" class="collapse">
                  <p class="bg-success">
                    Attributed networks nowadays are ubiquitous in a myriad of high-impact applications, such as social network analysis, financial fraud detection, and drug discovery. As a central analytical task on attributed networks, node classification has received much attention in the research community. In real-world attributed networks, a large portion of node classes only contain limited labeled instances, rendering a long-tail node class distribution. Existing node classification algorithms are unequipped to handle the few-shot node classes. As a remedy, few-shot learning has attracted a surge of attention in the research community. Yet, few-shot node classification remains a challenging problem as we need to address the following questions: (i) How to extract meta-knowledge from an attributed network for few-shot node classification? (ii) How to identify the informativeness of each labeled instance for building a robust and effective model? To answer these questions, in this paper, we propose a graph meta-learning framework -- Graph Prototypical Networks (GPN). By constructing a pool of semi-supervised node classification tasks to mimic the real test environment, GPN is able to perform meta-learning on an attributed network and derive a highly generalizable model for handling the target classification task. Extensive experiments demonstrate the superior capability of GPN in few-shot node classification.
                  </p>
                </div>
                <a href="https://github.com/kaize0409/GPN"> <button type="button" class="btn btn-primary btn-xs"> code </button> </a>
                <div style="height:30px;"></div>
              </div>
            </div>



            <!--
            <div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail" href="">
                  <img src="./img/TCSVT.jpg" alt="Pooling the Convolutional Layers in Deep ConvNets for Video Action Recognition">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Inductive Anomaly Detection on Attributed Networks</strong><br>
                <u>Kaize Ding</u>,, Jundong Li, Nitin Aagarwal and Huan Liu<br>
                <em>International Joint Conference on Artificial Intelligence (IJCAI) </em> 2020.<br>
                <a href="http://www.public.asu.edu/~kding9/pdf/IJCAI2020_Aegis.pdf"> <button type="button" class="btn btn-primary btn-xs"> pdf </button> </a>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bibtex6">bibtex</button>
                <div id="bibtex6" class="collapse">
                  <pre><tt>@InProceedings{ding2020inductive,
  title &nbsp&nbsp&nbsp&nbsp= {Inductive anomaly detection on attributed networks},
  author &nbsp&nbsp = {Ding, Kaize and Li, Jundong and Agarwal, Nitin and Liu, Huan},
  booktitle = {29th International Joint Conference on Artificial Intelligence, IJCAI 2020},
  year &nbsp&nbsp&nbsp = {2020},
}</tt></pre>
                </div>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#abstract6">abstract</button>
                <div id="abstract6" class="collapse">
                  <p class="bg-success">
                  </p>
                </div>
                <a href=""> <button type="button" class="btn btn-primary btn-xs"> code </button> </a>
                <div style="height:30px;"></div>
              </div>
            </div>
            -->

            <div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                  <img src="image/DOMINANT.png" alt="Adaptive Sparse Confidence-Weighted Learning for Online Feature Selection">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Deep Anomaly Detection on Attributed Networks with Graph Convolutional Networks</strong><br>
                <u>Kaize Ding</u>, Jundong Li, Rohit Bhanushali, and Huan Liu<br>
                <em>SIAM International Conference on Data Mining (<strong>SDM</strong>) </em> 2019.<br>
                <a href="http://www.public.asu.edu/~kding9/pdf/SDM2019_Deep.pdf"> <button type="button" class="btn btn-primary btn-xs"> pdf </button> </a>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bibtex10">bibtex</button>
                <div id="bibtex10" class="collapse">
                  <pre><tt>@InProceedings{ding2019deep,
  title &nbsp&nbsp&nbsp&nbsp= {Deep anomaly detection on attributed networks},
  author &nbsp&nbsp = {Ding, Kaize and Li, Jundong and Bhanushali, Rohit and Liu, Huan},
  booktitle = {Proceedings of the 2019 SIAM International Conference on Data Mining},
  year &nbsp&nbsp&nbsp = {2019},
}</tt></pre>
                </div>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#abstract10">abstract</button>
                <div id="abstract10" class="collapse">
                  <p class="bg-success">
                    Attributed networks are ubiquitous and form a critical component of modern information infrastructure, where additional node attributes complement the raw network structure in knowledge discovery. Recently, detecting anomalous nodes on attributed networks has attracted an increasing amount of research attention, with broad applications in various high-impact domains, such as cybersecurity, finance, and healthcare. Most of the existing attempts, however, tackle the problem with shallow learning mechanisms by ego-network or community analysis, or through subspace selection. Undoubtedly, these models cannot fully address the computational challenges on attributed networks. For example, they often suffer from the network sparsity and data nonlinearity issues, and fail to capture the complex interactions between different information modalities, thus negatively impact the performance of anomaly detection. To tackle the aforementioned problems, in this paper, we study the anomaly detection problem on attributed networks by developing a novel deep model. In particular, our proposed deep model: (1) explicitly models the topological structure and nodal attributes seamlessly for node embedding learning with the prevalent graph convolutional network (GCN); and (2) is customized to address the anomaly detection problem by virtue of deep autoencoder that leverages the learned embeddings to reconstruct the original data. The synergy between GCN and autoencoder enables us to spot anomalies by measuring the reconstruction errors of nodes from both the structure and the attribute perspectives. Extensive experiments on real-world attributed network datasets demonstrate the efficacy of our proposed algorithm.
                  </p>
                </div>
                <a href="https://github.com/kaize0409/GCN_AnomalyDetection"> <button type="button" class="btn btn-primary btn-xs"> code </button> </a>
                <div style="height:30px;"></div>
              </div>
            </div>


        <!--<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                  <img src="image/GraphUCB.png" alt="Adaptive Sparse Confidence-Weighted Learning for Online Feature Selection">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Interactive Anomaly Detection on Attributed Networks</strong><br>
                <u>Kaize Ding</u>, Jundong Li, and Huan Liu<br>
                <em>ACM International Conference on Web Search and Data Mining (<strong>WSDM</strong>) </em> 2019.<br>
                <a href="http://www.public.asu.edu/~kding9/pdf/WSDM2019_GraphUCB.pdf"> <button type="button" class="btn btn-primary btn-xs"> pdf </button> </a>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bibtex15">bibtex</button>
                <div id="bibtex15" class="collapse">
                  <pre><tt>@InProceedings{ding2019interactive,
  title &nbsp&nbsp&nbsp&nbsp= {Interactive anomaly detection on attributed networks},
  author &nbsp&nbsp = {Ding, Kaize and Li, Jundong and Liu, Huan},
  booktitle = {Proceedings of the twelfth ACM international conference on web search and data mining},
  year &nbsp&nbsp&nbsp = {2019},
}</tt></pre>
                </div>
                <button type="button" class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#abstract15">abstract</button>
                <div id="abstract15" class="collapse">
                  <p class="bg-success">
                    Performing anomaly detection on attributed networks concerns with finding nodes whose patterns or behaviors deviate significantly from the majority of reference nodes. Its success can be easily found in many real-world applications such as network intrusion detection, opinion spam detection and system fault diagnosis, to name a few. Despite their empirical success, a vast majority of existing efforts are overwhelmingly performed in an unsupervised scenario due to the expensive labeling costs of ground truth anomalies. In fact, in many scenarios, a small amount of prior human knowledge of the data is often effortless to obtain, and getting it involved in the learning process has shown to be effective in advancing many important learning tasks. Additionally, since new types of anomalies may constantly arise over time especially in an adversarial environment, the interests of human expert could also change accordingly regarding to the detected anomaly types. It brings further challenges to conventional anomaly detection algorithms as they are often applied in a batch setting and are incapable to interact with the environment. To tackle the above issues, in this paper, we investigate the problem of anomaly detection on attributed networks in an interactive setting by allowing the system to proactively communicate with the human expert in making a limited number of queries about ground truth anomalies. Our objective is to maximize the true anomalies presented to the human expert after a given budget is used up. Along with this line, we formulate the problem through the principled multi-armed bandit framework and develop a novel collaborative contextual bandit algorithm, named GraphUCB. In particular, our developed algorithm: (1) explicitly models the nodal attributes and node dependencies seamlessly in a joint framework; and (2) handles the exploration-exploitation dilemma when querying anomalies of different types. Extensive experiments on real-world datasets show the improvement of the proposed algorithm over the state-of-the-art algorithms.
                  </p>
                </div>
                <a href="https://github.com/kaize0409/GraphUCB"> <button type="button" class="btn btn-primary btn-xs"> code </button> </a>
                <div style="height:30px;"></div>
              </div>
            </div>-->
			

        <hr>







<!-- Competitions -->
        <div class="row" id="experiences" style="padding-top:60px; margin-top:-60px;">
          <div class="col-md-12">
            <h2>Professional Experiences</h2>
            <ul>
            <li> <b>Google Brain</b>, Research Intern, 2022</li>
            <li> <b>Microsoft Research</b>, Research Intern, 2021</li>
            <li> <b>Amazon Alexa AI</b>, Applied Scientist Intern, 2020</li>
            <li> <b>Microsoft Research Asia</b>, Research Intern, 2016, 2017</li>
            <li> <b>Chinese University of Hong Kong</b>, Research Assistant, 2017</li>
            <li> <b>Meituan</b>, Intern, 2015</li>
            <li> <b>Sogou</b>, Intern, 2014</li>
          </ul>

          </div> 
        </div> 

        <hr>




<!-- Academic Service -->
       <div class="row" id="services" style="padding-top:60px; margin-top:-60px;">
         <div class="col-md-12">
           <h2>Services</h2>
           <b>Program Committee</b>
           <p>KDD'22, WSDM'22, IJCAI'22, CIKM'21, ECML-PKDD'21, EMNLP21, ACL'21, IJCAI'21, IJCAI'20, ECML-PKDD'20</p>
         
           <b>External Reviewer</b>
           <p>KDD'19, WWW'19, SIGIR'18, ASONAM'18</p>
         
         
         </div> 
       </div> 


       <hr>

<!-- Honor -->
      <div class="row" id="honor" style="padding-top:60px; margin-top:-60px;">
        <div class="col-md-12">
          <h2>Honors and Awards</h2>
          <ul>
           <li><b>SDM Best Posters (runner up) Award</b>, 2022</li>
           <li><b>ASU Graduate College Completion Fellowship</b>, 2022</li>
           <li><b>ASU GPSA Outstanding Research Award</b>, 2022</li>
           <li><b>ASU CIDSE Doctoral Fellowship</b>, 2021</li>
           <li><b>ASU Engineering Graduate Fellowship</b>, 2019, 2020</li>
           <li><b>Microsoft Research Asia Stars of Tomorrow (Excellent Intern Award)</b>, 2017</li>
          </ul>
          
        
        </div> 
      </div> 

      <hr>






      <!--
      <div align="middle" height="200">
        <a href="" title="Visit tracker"><img src="" ></a>
      </div>
      -->

      <div class="container">
        <footer>
          <p align="right"><small>&nbsp; Last update 2021</small></p>
        </footer>
        <div style="height:10px;"></div>
      </div>


      <script src="js/jquery-1.11.1.min.js"></script>
      <script src="js/bootstrap.min.js"></script>
      <script src="js/docs.min.js"></script>
      

    </body>
</html>


